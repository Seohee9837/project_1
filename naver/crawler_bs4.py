import os
import requests
from bs4 import BeautifulSoup as bs
import time
import pandas as pd
import datetime
from tqdm import tqdm
import fake_useragent #pyinstaller ì‚¬ìš© ë¶ˆê°€ ìš°ì”¨...
from openpyxl.cell.cell import ILLEGAL_CHARACTERS_RE
import re
from collections import Counter

#ì •ì  í¬ë¡¤ëŸ¬
def CWBS(page_start, page_end, url, start_date, end_date, stock_code, target_date):
    error_count = 0 #ê´€ë¦¬ì ì‚­ì œ ë§í¬ ìˆ˜ ì„¸ê¸°

    #data í´ë” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
    data_folder = 'data'
    if not os.path.exists(data_folder):
        os.makedirs(data_folder)
        print("data í´ë” ìƒì„±")

    #ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    log_file_name = 'log.txt'
    if os.path.isfile(log_file_name):
        print("log íŒŒì¼ ì¡´ì¬")
    else:
        f = open("log.txt", 'w')
        f.close()
        print("ë¡œê·¸íŒŒì¼ ìƒì„±")

    #í¬ë¡¤ë§ ì‹œì‘ logì— ì¶œë ¥
    file = open("log.txt", "a", encoding="UTF-8")
    file.write(f"\n---------------------------------\n ì •ì  í¬ë¡¤ë§ ì‹œì‘\n ì‹œì‘ í˜ì´ì§€: {page_start}, ë§ˆì§€ë§‰ í˜ì´ì§€: {page_end}\n")
    file.close()

    start_time = time.time()
    #í•„ìš” ë¦¬ìŠ¤íŠ¸
    date_list = [] #ë‚ ì§œ
    title_list = [] #ì œëª©
    content_list = [] #ë³¸ë¬¸
    url_list = [] #í¬ë¡¤ë§ëœ url

    #í¬ë¡¤ë§ ì‹œì‘
    print("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    for url_p in tqdm(url):
        try: #ê´€ë¦¬ì ì‚­ì œ ë§í¬ ìƒê¸°ë©´ except ì‹¤í–‰ í›„ ë‹¤ìŒ ë§í¬ í¬ë¡¤ë§
            user_agent = fake_useragent.UserAgent()
            headers = {
                    'Referer': f'https://finance.naver.com/item/board.naver?code={stock_code}',
                    'User-Agent': user_agent.random
                }
            url = "https://finance.naver.com" + url_p #ë§í¬ì— item ë’·ë¶€ë¶„ë§Œ í¬í•¨ë˜ì–´ìˆê¸°ì— ì•ë¶€ë¶„ ì¶”ê°€
            response_url_html = requests.get(url=url, headers=headers) #ë§í¬ ìš”ì²­
            url_html_text = response_url_html.text #ë°›ì€ jsoníŒŒì¼ì—ì„œ textê°’ë§Œ ì¶”ì¶œ
            html = bs(url_html_text, 'html.parser') #html íŒŒì‹±

            #ìš”ì†Œ ì ‘ê·¼
            date_element = html.select_one('.gray03.p9.tah')
            if not date_element:
                print(f"ë‚ ì§œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {url}")
                error_count += 1
                continue
            date = date_element.text
            
            #ë³¸ë¬¸ í¬ë¡¤ë§ - ì—¬ëŸ¬ ì„ íƒì ì‹œë„
            content = ""
            content_selectors = ['.view_se', '.se-main-container', '.se-component-content', '.post_content']
            for selector in content_selectors:
                content_element = html.select_one(selector)
                if content_element:
                    content_not_cleaned = content_element.get_text(strip=True)
                    content = content_not_cleaned
                    break
            
            #ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì •ë¦¬
            if content:
                content = content.replace("\n", " ").replace("\r", " ").replace("\t", " ")
                content = " ".join(content.split())  # ì—°ì†ëœ ê³µë°± ì œê±°
                content = ILLEGAL_CHARACTERS_RE.sub(r'', content)
            else:
                content = "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            title_element = html.select_one('.c.p15')
            if not title_element:
                print(f"ì œëª© ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {url}")
                error_count += 1
                continue
            title_not_cleaned = title_element.text
            title = title_not_cleaned.replace("#", "").replace("â– ", "").replace("[", "").replace("]", "") #ì œëª©ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
            title = ILLEGAL_CHARACTERS_RE.sub(r'', title)

            #í¬ë¡¤ë§í•œ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸°
            date_list.append(date[:10]) #year, month, dayë§Œ í¬ë¡¤ë§
            title_list.append(title)
            content_list.append(content)
            url_list.append(url) #ë””ë²„ê¹…ìš© url
            
        except Exception as e:
            print(f"ê²Œì‹œê¸€ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {url}")
            print(f"ì—ëŸ¬ ë‚´ìš©: {str(e)}")
            error_count += 1
            continue

    #dataframe ìƒì„± í›„ í¬ë¡¤ë§ í•œ ê²ƒë“¤ ì „ë¶€ ë‹´ê¸°
    df = pd.DataFrame()
    df['date'] = date_list
    df['title'] = title_list
    df['content'] = content_list
    df['url'] = url_list

    # í•´ë‹¹ ë‚ ì§œë§Œ í•„í„°ë§
    filtered_df = df[df['date'] == target_date]
    print(f"ì „ì²´ í¬ë¡¤ë§ ë°ì´í„°: {len(df)}ê°œ")
    print(f"í•„í„°ë§ëœ ë°ì´í„° ({target_date}): {len(filtered_df)}ê°œ")

    #CSVë¡œ ì €ì¥ (í•„í„°ë§ëœ ë°ì´í„°ë§Œ)
    filtered_df.to_csv(f"data/{stock_code}_{target_date}_filtered.csv", index = False, sep='\t')
    
    # í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰
    extract_top_keywords(filtered_df, stock_code, target_date)
    
    # í†µê³„ íŒŒì¼ ìƒì„±
    create_statistics_file(stock_code, target_date, len(df), len(filtered_df), error_count, start_date, end_date)
    
    #ë””ë²„ê¹…ìš© ì‹œê°„ ì²´í¬
    end_time = time.time()
    sec = (end_time - start_time)
    result_t = str(datetime.timedelta(seconds=sec)).split(".") #ì†Œìˆ˜ì  ì´í›„ë¡œ ìë¥´ê¸°
    print(f"ì‹œê°„ : {result_t[0]}") #ì˜ë¦° ì†Œìˆ˜ì ì€ [1]
    file = open("log.txt", "a", encoding="UTF-8") #ë§ˆë¬´ë¦¬ ë¡œê·¸
    file.write(f"ê±¸ë¦° ì‹œê°„ : {result_t[0]}, error_count : {error_count}")
    file.close()

def create_statistics_file(stock_code, target_date, total_crawled, filtered_count, error_count, start_date, end_date):
    """í¬ë¡¤ë§ í†µê³„ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    stats_content = f"""ë„¤ì´ë²„ ê¸ˆìœµ ê²Œì‹œê¸€ í¬ë¡¤ë§ í†µê³„
==========================================
ìƒì„± ì‹œê°„: {current_time}
ì¢…ëª© ì½”ë“œ: {stock_code}
ê²€ìƒ‰ ê¸°ê°„: {start_date} ~ {end_date}
ëŒ€ìƒ ë‚ ì§œ: {target_date}

í¬ë¡¤ë§ ê²°ê³¼:
- ì „ì²´ í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ ìˆ˜: {total_crawled:,}ê°œ
- í•„í„°ë§ëœ ê²Œì‹œê¸€ ìˆ˜ ({target_date}): {filtered_count:,}ê°œ
- ì—ëŸ¬ ë°œìƒ ìˆ˜: {error_count:,}ê°œ
- ì„±ê³µë¥ : {((total_crawled - error_count) / total_crawled * 100):.1f}% (ì—ëŸ¬ ì œì™¸)

íŒŒì¼ ì €ì¥ ìœ„ì¹˜:
- í•„í„°ë§ëœ ë°ì´í„°: data/{stock_code}_{target_date}_filtered.csv
- ë¡œê·¸ íŒŒì¼: log.txt

=========================================="""
    
    # í†µê³„ íŒŒì¼ ì €ì¥
    stats_filename = f"data/{stock_code}_{target_date}_statistics.txt"
    with open(stats_filename, "w", encoding="UTF-8") as f:
        f.write(stats_content)
    
    print(f"\nğŸ“Š í¬ë¡¤ë§ í†µê³„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {stats_filename}")
    print(f"ì´ í¬ë¡¤ë§ëœ ê²Œì‹œê¸€ ìˆ˜: {total_crawled:,}ê°œ")
    print(f"í•„í„°ë§ëœ ê²Œì‹œê¸€ ìˆ˜: {filtered_count:,}ê°œ")

def extract_top_keywords(df, stock_code, target_date):
    """í¬ë¡¤ë§ëœ ë°ì´í„°ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ë‹¨ì–´ 10ê°œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # ì œëª©ê³¼ ë³¸ë¬¸ì„ í•©ì³ì„œ ë¶„ì„
    all_text = ""
    for _, row in df.iterrows():
        all_text += str(row['title']) + " " + str(row['content']) + " "
    
    # í•œê¸€ ë‹¨ì–´ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
    korean_words = re.findall(r'[ê°€-í£]{2,}', all_text)
    
    # ë¶ˆìš©ì–´ ëª©ë¡ (ì œê±°í•  ë‹¨ì–´ë“¤)
    stop_words = {
        'ìˆìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤',
        'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ë˜í•œ', 'ë˜ëŠ”', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°',
        'ì´ê²ƒ', 'ì €ê²ƒ', 'ê·¸ê²ƒ', 'ë¬´ì—‡', 'ì–´ë–¤', 'ì–´ë–»ê²Œ', 'ì–¸ì œ', 'ì–´ë””ì„œ',
        'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì–´ì œ', 'ì§€ê¸ˆ', 'ì´ì œ', 'ê·¸ë•Œ', 'ì–¸ì œë‚˜',
        'ë§¤ìš°', 'ë„ˆë¬´', 'ì •ë§', 'ì§„ì§œ', 'ì•„ì£¼', 'í›¨ì”¬', 'ë”ìš±',
        'ë³´ê³ ', 'ìˆë‹¤', 'ì—†ë‹¤', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤',
        'ì´ëŸ°', 'ì €ëŸ°', 'ê·¸ëŸ°', 'ì–´ë–¤', 'ë¬´ìŠ¨', 'ì–´ëŠ', 'ëª‡',
        'ë•Œë¬¸', 'ìœ„í•´', 'í†µí•´', 'ë”°ë¼', 'ê´€ë ¨', 'ëŒ€í•œ', 'ìˆëŠ”', 'ì—†ëŠ”',
        'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”', 'í•˜ëŠ”', 'ë˜ëŠ”', 'ìˆëŠ”', 'ì—†ëŠ”',
        'ìˆì—ˆë‹¤', 'ê²ƒì´ë‹¤'
    }
    
    # ë¶ˆìš©ì–´ ì œê±°
    filtered_words = [word for word in korean_words if word not in stop_words and len(word) >= 2]
    
    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    word_counts = Counter(filtered_words)
    
    # ìƒìœ„ 10ê°œ ë‹¨ì–´ ì¶”ì¶œ
    top_10_words = word_counts.most_common(10)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ” {stock_code} ì¢…ëª©ì˜ ìƒìœ„ í‚¤ì›Œë“œ 10ê°œ ({target_date})")
    print("=" * 50)
    for i, (word, count) in enumerate(top_10_words, 1):
        print(f"{i:2d}. {word:<10} - {count:3d}íšŒ ì–¸ê¸‰")
    
    # í‚¤ì›Œë“œ íŒŒì¼ ì €ì¥
    keyword_filename = f"data/{stock_code}_{target_date}_keywords.txt"
    with open(keyword_filename, "w", encoding="UTF-8") as f:
        f.write(f"{stock_code} ì¢…ëª© ìƒìœ„ í‚¤ì›Œë“œ ë¶„ì„ ({target_date})\n")
        f.write("=" * 50 + "\n")
        f.write(f"ì´ ê²Œì‹œê¸€ ìˆ˜: {len(df)}ê°œ\n\n")
        f.write("ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ:\n")
        for i, (word, count) in enumerate(top_10_words, 1):
            f.write(f"{i:2d}. {word:<10} - {count:3d}íšŒ ì–¸ê¸‰\n")
    
    print(f"\nğŸ“ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {keyword_filename}")
    print(f"ì´ ê²Œì‹œê¸€ ìˆ˜: {len(df)}ê°œ")
    
    return top_10_words